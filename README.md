# CRAFT

# _テキスト検出のための文字領域認識_

Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun, and Hwalsuk Lee∗ 
Clova AI Research, NAVER Corp.

## 要旨
ニューラルネットワークに基づくシーンテキスト検知方法が最近浮上し、有望な結果を得ました。
従来の方法では、文字間の関係性と文字間の親和性を検出するために新しいシーン検知方法を提案します。
個々の文字レベルの注釈の欠如を克服するために、学習した中間モデルで獲得した実像のための文字レベルの注釈と文字レベルのグランドトゥルースの両方を利用します。
文字間の親和性を推定するために、ネットワークは新規提案された親和性のための表現で訓練されます。
自然画像の中の高カーブテキストを含む6つのベンチマークの拡張実験と、文字レベル検出が最先端検知器を大幅に上回ることを実証します。
その結果、提案手法は恣意的、カーブ、変形文などの複雑なシーン画像の検知において、高柔軟性を保証します。

## 序章
瞬間翻訳、画像検索、地中検索、盲点検など、数多くのアプリケーションがあり、コンピュータ視野で注目されています。
最近、ディープラーニングをベースにしたテキストデテクター(8、40、40、21、10、12、24、25、32、26)は、ワードライブボックスのローカライズを主にしています。
しかし、単一バウンディングボックスでは検知しにくい曲線、変形、極端に長いテキストなど、難しい場合には苦しみます。
代わりに、文字をボトムアップで結びつけることでテキストにチャレンジすると、文字レベル認識は多くのメリットがあります。
既存のテキストデータセットの大部分は文字レベルの注釈ではなく、文字レベルのグランドトゥルースを得るために必要な作業は高すぎます。
本稿では個々の文字領域をローカライズし、検知文字をテキスト例にリンクするテキスト検知器を提案します。
文字領域認知のためのCRAFTと呼ばれる枠文字領域認知のために、文字領域スコアと親和スコアを出して複雑なニューラルネットワークで設計します。
地域スコアはイメージの個々の文字をローカライズし、親和スコアは各文字を一例にまとめて使います。
文字レベルの注釈の欠如を補うために、既存のリアルワードレベルデータセットの文字レベルグランドトゥルースを見積もる弱教師あり学習枠を提案します。  
![Figure1](https://github.com/inouetaka/CRAFT/blob/master/images/figure1.png)

## 関連作業
ディープラーニング登場前のシーン検知の主なトレンドはボトムアップであり、手作りの機能が主に使われていた(MSER[27]やSWT[5])。最近はSSD[20]、Faster R-CNN[30]、FCN[23]のような人気物体検知/セグメンテーション法を採用してディープラーニングベースのテキスト検知器が提案されている。
### 回帰ベースのテキスト探知器
人気物検知器を用いた様々なテキストレグレージョン適応が提案されています。一般的な物とは違い、様々なアスペクト比で不規則な形でテキストが提示されることが多いです。この問題に対処するために、テキストボックス[18] 変形コンカーネルとアンカーボックスは様々なテキスト形状を効果的に捕捉するために改良されています。DMPNet[22] は四角いスライディングウィンドウを取り入れることで問題のさらなる減らしに努めました。最近では、回転感覚回帰検知器(RSDD) [19] ボレーションフィルターを積極的に回転させることで不変の特徴を最大限に活用することが提案されました。

### セグメンテーションベースのテキスト探知機
もう一つの共通アプローチは、ピクセルレベルでテキスト領域を探求するセグメンテーションの手法です。マルチスケールFCN[7]、ホリスティック予測[37]、PixelLink[4]などの単語境界領域を推定してテキストを検出するアプローチはセグメンテーションをベースに提案しました。SSTD[8]は特徴レベルの背景干渉を減らして関連領域を強化するアテンションメカニズムを用いて回帰とセグメンテーションの両方の恩恵を受けようとしました。最近、テキストスネーク[24]は幾何学属性と共にテキスト領域とセンターラインを予測してテキストインスタンスを検知することを提案しました。

### エンドツーエンドのテキスト探知機
認識結果を活用して検知精度を高めるために、一斉検知と認識モジュールを同時に教育します。FOTS[21]とEAA[10]の一般検知と認識方法を組み合わせて、エンドツーエンドでトレーニングします。マスクテキストスポッター[25]は、統一モデルを利用して認識作業を意味論セグメンテーション問題として扱いました。認識モジュールでのトレーニングは、テキスト感知器がテキストのような背景の雑然としたものになるのを助けるのは明白です。
ほとんどの方法では単語でテキストを検知しますが、検知のために単語にするのは些細なことではありません。なぜなら単語は意味、空間、色など様々な基準で分けることができるからです。また、単語のセグメンテーションの境界は厳密に定義できないので、単語のセグメント自体は明確な意味合いがありません。この単語の注釈の曖昧さは回帰とセグメンテーションの両方のアプローチのためのグランドトゥルースの意味を希釈します。

### 文字レベルのテキスト探知機
チャンら[39]は、MSERで蒸留したテキストブロック候補で文字レベル感知器を提案しました。[27]では個々の文字を識別するためにMSERを使用することで、対照シーンなどの特定の状況下での感知力強さを制限しています。　　
ヤオら[37]は、文字領域の地図と、文字レベルの注釈が必要な連動方向の予測マップを使いました。明示文字レベル予測の代わりに、セグリンク[32]はテキストグリッド(一部テキストセグメント)を狩り、これらのセグメントを連想させて追加リンク予測を行います。マスクテキストスポッター[25]は文字レベル確率マップを予測しますが、個々の文字を見分ける代わりにテキスト記録に使用しました。
弱教師あり学習の枠組みで文字レベル感知器の学習を行うWordSup[12]の発想にインスパイアされた作品です。しかし、Wordsupの欠点は、文字の表現が長方形のアンカーで形成されていることで、カメラの見方によって誘導される文字のパース変形に弱いことです。また、バックボーン構造の性能(SSDを使用し、アンカーボックスの数と大きさで制限されていること)に縛られています。
