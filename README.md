# CRAFT

# _テキスト検出のための文字領域認識_

Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun, and Hwalsuk Lee∗ 
Clova AI Research, NAVER Corp.

## 要旨
ニューラルネットワークに基づくシーンテキスト検知方法が最近浮上し、有望な結果を得ました。
従来の方法では、文字間の関係性と文字間の親和性を検出するために新しいシーン検知方法を提案します。
個々の文字レベルの注釈の欠如を克服するために、学習した中間モデルで獲得した実像のための文字レベルの注釈と文字レベルのグランドトゥルースの両方を利用します。
文字間の親和性を推定するために、ネットワークは新規提案された親和性のための表現で訓練されます。
自然画像の中の高カーブテキストを含む6つのベンチマークの拡張実験と、文字レベル検出が最先端検知器を大幅に上回ることを実証します。
その結果、提案手法は恣意的、カーブ、変形文などの複雑なシーン画像の検知において、高柔軟性を保証します。

## 1.序章
瞬間翻訳、画像検索、地中検索、盲点検など、数多くのアプリケーションがあり、コンピュータ視野で注目されています。
最近、ディープラーニングをベースにしたテキストデテクター(8、40、40、21、10、12、24、25、32、26)は、ワードライブボックスのローカライズを主にしています。
しかし、単一バウンディングボックスでは検知しにくい曲線、変形、極端に長いテキストなど、難しい場合には苦しみます。
代わりに、文字をボトムアップで結びつけることでテキストにチャレンジすると、文字レベル認識は多くのメリットがあります。
既存のテキストデータセットの大部分は文字レベルの注釈ではなく、文字レベルのグランドトゥルースを得るために必要な作業は高すぎます。
本稿では個々の文字領域をローカライズし、検知文字をテキスト例にリンクするテキスト検知器を提案します。
文字領域認知のためのCRAFTと呼ばれる枠文字領域認知のために、文字領域スコアと親和スコアを出して複雑なニューラルネットワークで設計します。
領域スコアはイメージの個々の文字をローカライズし、親和スコアは各文字を一例にまとめて使います。
文字レベルの注釈の欠如を補うために、既存のリアルワードレベルデータセットの文字レベルグランドトゥルースを見積もる弱教師あり学習枠を提案します。  
![Figure1](https://github.com/inouetaka/CRAFT/blob/master/images/figure1.png)

## 2.関連作業
ディープラーニング登場前のシーン検知の主なトレンドはボトムアップであり、手作りの機能が主に使われていた(MSER[27]やSWT[5])。最近はSSD[20]、Faster R-CNN[30]、FCN[23]のような人気物体検知/セグメンテーション法を採用してディープラーニングベースのテキスト検知器が提案されている。
### 回帰ベースのテキスト探知器
人気物検知器を用いた様々なテキストレグレージョン適応が提案されています。一般的な物とは違い、様々なアスペクト比で不規則な形でテキストが提示されることが多いです。この問題に対処するために、テキストボックス[18] 変形コンカーネルとアンカーボックスは様々なテキスト形状を効果的に捕捉するために改良されています。DMPNet[22] は四角いスライディングウィンドウを取り入れることで問題のさらなる減らしに努めました。最近では、回転感覚回帰検知器(RSDD) [19] ボレーションフィルターを積極的に回転させることで不変の特徴を最大限に活用することが提案されました。

### セグメンテーションベースのテキスト探知機
もう一つの共通アプローチは、ピクセルレベルでテキスト領域を探求するセグメンテーションの手法です。マルチスケールFCN[7]、ホリスティック予測[37]、PixelLink[4]などの単語境界領域を推定してテキストを検出するアプローチはセグメンテーションをベースに提案しました。SSTD[8]は特徴レベルの背景干渉を減らして関連領域を強化するアテンションメカニズムを用いて回帰とセグメンテーションの両方の恩恵を受けようとしました。最近、テキストスネーク[24]は幾何学属性と共にテキスト領域とセンターラインを予測してテキストインスタンスを検知することを提案しました。

### エンドツーエンドのテキスト探知機
認識結果を活用して検知精度を高めるために、一斉検知と認識モジュールを同時に教育します。FOTS[21]とEAA[10]の一般検知と認識方法を組み合わせて、エンドツーエンドでトレーニングします。マスクテキストスポッター[25]は、統一モデルを利用して認識作業を意味論セグメンテーション問題として扱いました。認識モジュールでのトレーニングは、テキスト感知器がテキストのような背景の雑然としたものになるのを助けるのは明白です。
ほとんどの方法では単語でテキストを検知しますが、検知のために単語にするのは些細なことではありません。なぜなら単語は意味、空間、色など様々な基準で分けることができるからです。また、単語のセグメンテーションの境界は厳密に定義できないので、単語のセグメント自体は明確な意味合いがありません。この単語の注釈の曖昧さは回帰とセグメンテーションの両方のアプローチのためのグランドトゥルースの意味を希釈します。

### 文字レベルのテキスト探知機
チャンら[39]は、MSERで蒸留したテキストブロック候補で文字レベル感知器を提案しました。[27]では個々の文字を識別するためにMSERを使用することで、対照シーンなどの特定の状況下での感知力強さを制限しています。　　
ヤオら[37]は、文字領域の地図と、文字レベルの注釈が必要な連動方向の予測マップを使いました。明示文字レベル予測の代わりに、セグリンク[32]はテキストグリッド(一部テキストセグメント)を狩り、これらのセグメントを連想させて追加リンク予測を行います。マスクテキストスポッター[25]は文字レベル確率マップを予測しますが、個々の文字を見分ける代わりにテキスト記録に使用しました。
弱教師あり学習の枠組みで文字レベル感知器の学習を行うWordSup[12]の発想にインスパイアされた作品です。しかし、Wordsupの欠点は、文字の表現が長方形のアンカーで形成されていることで、カメラの見方によって誘導される文字のパース変形に弱いことです。また、バックボーン構造の性能(SSDを使用し、アンカーボックスの数と大きさで制限されていること)に縛られています。  
![Figure2](https://github.com/inouetaka/CRAFT/blob/master/images/figure2.png)

## 3.方法論
主な目的は、個々の文字を自然画像で正確にローカライズすることです。そのために、文字領域や文字間の親和性を予測する深層ネットワークを学習しています。公的文字レベルのデータセットがないので、弱教師あり学習を受けています。

### 3.1.構成
バッチノーマライゼーションでVGG-16[34]をベースとした全結合ネットワーク構造をバックボーンに採用しました。低レベルの特徴を集約する点でU-net[31]に似たデコーディング部分はスキップ接続があります。最終出力はスコアマップとして2チャンネルあります。リージョンスコアと親和スコアです。ネットワーク構造は図2で計画的に図示しています。

### 3.2.学習  

### 3.2.1 グランドトゥルースラベル生成
学習イメージ毎に、領域スコアのグランドトゥルースラベルと文字境界ボックスの親和スコアを作成します。領域スコアは与えられたピクセルが文字の中心である確率を表し、親和スコアは隣接文字の間隔のセンター確率を表します。
各ピクセルに個別にラベルを貼る連続セグメンテーションマップと違い、ガウシアンヒートマップで文字センターの確率をエンコードします。グランドトゥルースにこだわらない領域に対処する際の高柔軟性のため、ポーズ推定ワーク[1,29]などの他の用途で使用しています。領域スコアと親和スコアの両方を習得するためにヒートマップ表現を使用します。
図3は合成イメージのラベル生成パイプラインを要約します。境界ボックス内の各ピクセルの直接的な正規分布の値を計算するのはとても時間がかかります。イメージ上の文字の境界ボックスは概ね歪んでいるので、領域スコアと親和スコアの両方のグランドトゥルースをおおよそに生成します。1)2次元等方性ガウス図を準備します。2)ガウシアン図と各文字ボックスの間のパースチェンジ。3)ウォープガウシアンマップをボックスエリアにします。
親和スコアの地盤部分は、図3のように隣接文字ボックスで親和性ボックスを定義します。それぞれのキャラクターボックスの対角に対角になるように対角線を描くことで、上と下の三角形と呼ぶ三角形を生成します。次に、隣接する文字ボックスペアでは、上と下の三角形の中心を箱の隅に設けて親和性ボックスを作ります。
グランドトゥルースの定義を提案すると、小さい受信場ではあるが、長さの大きい文章や長さのある文章を十分に検知できるようになっている。一方、回帰ボックスのような従来のアプローチは、そのような場合には受容場が大きい必要がある。我々の文字レベル検知は、文章例全体ではなく、入り組んだフィルターとインターキャラクターのみに集中することができるようになっている。
![Figure3](https://github.com/inouetaka/CRAFT/blob/master/images/figure3.png)

### 3.2.2 弱教師付き学習
合成データセットとは異なり、データセットのリアル画像は通常単語レベルの注釈があります。ここでは、図4に要約したように、統計的に各単語レベルの注釈から、弱い教師で文字ボックスを作ります。単語レベルの注釈でリアルイメージを設けた場合、学習中間モデルは、クロップされた単語イメージの文字領域スコアを予測して、文字レベルの境界ボックスを作ります。中間モデルの予測の信頼性を反映するため、トレーニング中の重さ学習に使われるグランドトゥルース文字の数で割った検出文字の数に比例して、各単語ボックス上の信頼図の値を算出します。
![Figure4](https://github.com/inouetaka/CRAFT/blob/master/images/figure4.png)  

図6は文字の割り振りの全工程を示しています。まず、オリジナルイメージから言葉レベルのイメージを描きます。第2に、最新のトレーニングを受けたモデルは領域のスコアを予測します。第3に、文字のバウンディングボックスを形成するために使われるキャラクタ領域の分割に使います。最後に、文字ボックスのコーディネートは、刈り込み段階から変換することでオリジナルイメージコーディネートに戻します。領域のスコアは擬似グランドトゥルース(pseudoGTs)と親和スコアは、図3の手順で作成できます。獲得した四角い文字レベルのバウンディングボックスで行います。

モデルのトレーニングは不完全な擬似GTでトレーニングします。もしモデルが不正確な領域スコアでトレーニングされれば、文字領域で出力がぼやけてしまうかもしれません。これを防ぐために、モデルで発生する擬似GTの品質を測ります。幸いにも文字の長さである注釈には非常に強いキューがあります。ほとんどのデータセットでは単語の書き継ぎが設けられており、単語の長さは偽GTの信頼度を評価するのに使えます。
